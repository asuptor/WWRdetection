{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcqgfSgncq52"
   },
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQ9hvL-rci6Q"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "REQUIREMENTS BEFORE RUNNING THIS NOTEBOOK:\n",
    "\n",
    "1.  Split OSM building polygons at vertices --> called the \"splitlines\" layer.\n",
    "\n",
    "2.  Prepare the dataset to identify street-facing segments, using the provided script in this package.\n",
    "\n",
    "3.  Review the street-facing segments in GIS, making manual adjustments as required.\n",
    "\n",
    "4.  In GIS, calculate the following geometry attributes, using meters, decimal degrees and\n",
    "    the coordinate system WGS 1984 Web Mercator Auxiliary Sphere:\n",
    "    \"Center_Lon\", \"Center_Lat\"  --> longitude and latitude of central point of each line segment.\n",
    "    \"Start_Lon\", \"Start_Lat\"    --> these become tuple coordinates for corner_a or corner_b. From GIS,\n",
    "                                it is unknown which if the start or end coordinates are the left or right\n",
    "                                side of the image, so the script determines this and renames these as\n",
    "                                corner 1 (left) and corner 2 (right).\n",
    "    \"End_Lon\", \"End_Lat\"        --> same as above, but the other corner of the line segment.\n",
    "    \"LINE_BEARING\"              --> line bearing of each line segment, from 0 to 360 degrees.\n",
    "    \"LINE_LENGTH\"               --> the geodesic length of each line segment. While not used in\n",
    "                                the functions in this notebook, line length is required for subsequent\n",
    "                                scripts in this package, so one should calculate this in GIS prior to export.\n",
    "\n",
    "    * Make sure to re-calculate all of the above if any line segments are merged during manual review.\n",
    "\n",
    "    The following columns are required for the notebook and can be created in this notebook, or elsewhere.\n",
    "    \"osm_id_final\"  -->   a unique identifier for each building segment, usually adding \"_1\", \"_2\", etc. to the osm_id.\n",
    "    \"image_id\"      -->   can be the same as osm_id_final for initial extraction, but in future additional\n",
    "                          suffixes may be added such as \"_left\" or \"_right\" if some extracted images need to be split\n",
    "                          in case of multiple buildings represented by one polygon in OSM.\n",
    "\n",
    "    \"perp_angle\"    -->   the angle from the GSV camera in the street to a street-facing building line segment.\n",
    "\n",
    "    Once the above three columns are created, it is suggested to save/export the dataframe to allow consistent\n",
    "    reuse of the osm_id_final and image_id columns in subsequent scripts.\n",
    "\n",
    "5.  Filter the \"splitlines\" layer to include only street-facing segments, and export from GIS to Excel:\n",
    "    --> this notebook uses the filename 'frontlines_for_extraction.xlsx'\n",
    "\n",
    "\n",
    "* Recommended to use high-RAM runtime for this notebook\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvZsaRIuhjLR"
   },
   "source": [
    "# Install & import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4864,
     "status": "ok",
     "timestamp": 1745312289946,
     "user": {
      "displayName": "Anthony Suppa",
      "userId": "01433471648786880681"
     },
     "user_tz": -120
    },
    "id": "0gi3VdQNhHIX",
    "outputId": "19506f1d-b794-40d5-9d24-eede8965c348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google_streetview\n",
      "  Downloading google_streetview-1.2.9.tar.gz (7.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting kwconfig (from google_streetview)\n",
      "  Downloading kwconfig-1.1.7.tar.gz (4.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google_streetview) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google_streetview) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google_streetview) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google_streetview) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google_streetview) (2025.1.31)\n",
      "Building wheels for collected packages: google_streetview, kwconfig\n",
      "  Building wheel for google_streetview (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for google_streetview: filename=google_streetview-1.2.9-py3-none-any.whl size=9777 sha256=c0b3152759fd8980cb085b51c9ed583b0771fc3b92d389f4094ac6b3ab7fd20d\n",
      "  Stored in directory: /root/.cache/pip/wheels/8f/55/d0/074e47d0e3fede14e60ddcd7b1a59681e1f1c3fd5b56cef79d\n",
      "  Building wheel for kwconfig (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for kwconfig: filename=kwconfig-1.1.7-py3-none-any.whl size=4974 sha256=69eb86fda7469371d119cca913de19538885d0ed0a13aa471c00cea56e2ea173\n",
      "  Stored in directory: /root/.cache/pip/wheels/5d/ae/f3/4f084ead544ae0187acf5ef586c5ee24ec92e1029b3383a8ac\n",
      "Successfully built google_streetview kwconfig\n",
      "Installing collected packages: kwconfig, google_streetview\n",
      "Successfully installed google_streetview-1.2.9 kwconfig-1.1.7\n"
     ]
    }
   ],
   "source": [
    "pip install google_streetview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18878,
     "status": "ok",
     "timestamp": 1745425734609,
     "user": {
      "displayName": "Anthony Suppa",
      "userId": "01433471648786880681"
     },
     "user_tz": -120
    },
    "id": "SFSeg8wFeIQ5",
    "outputId": "a8077b2e-a3a2-4531-ed33-87a8acc8db3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# import google_streetview.api\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1745425736401,
     "user": {
      "displayName": "Anthony Suppa",
      "userId": "01433471648786880681"
     },
     "user_tz": -120
    },
    "id": "L_2twJLRg1vo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import cv2\n",
    "import json\n",
    "import pyproj\n",
    "gd = pyproj.Geod(ellps='WGS84')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PGNdfHQhfFU"
   },
   "source": [
    "# Load and format dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 157,
     "status": "ok",
     "timestamp": 1745317402355,
     "user": {
      "displayName": "Anthony Suppa",
      "userId": "01433471648786880681"
     },
     "user_tz": -120
    },
    "id": "W4wWqWrki_RG",
    "outputId": "1116fbb2-36d3-434b-dfd1-e774e0a442ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory contents:  []\n"
     ]
    }
   ],
   "source": [
    "# Set path for project directory\n",
    "PROJECT_DIR = # ADD PATH TO PROJECT DIRECTORY, e.g. '/content/drive/MyDrive/Project_Name'\n",
    "print('directory contents: ', os.listdir(PROJECT_DIR))\n",
    "os.chdir(PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1745425741273,
     "user": {
      "displayName": "Anthony Suppa",
      "userId": "01433471648786880681"
     },
     "user_tz": -120
    },
    "id": "i_gUWh6JemCd"
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = # ADD PATH TO DATA DIRECTORY, e.g. '/content/drive/MyDrive/Project_Name/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 369,
     "status": "ok",
     "timestamp": 1745425927187,
     "user": {
      "displayName": "Anthony Suppa",
      "userId": "01433471648786880681"
     },
     "user_tz": -120
    },
    "id": "UuW_P6b4yhOv",
    "outputId": "5bcf8555-a48a-4d17-b78c-ade222bafd97"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"frontlines_df\",\n  \"rows\": 2393,\n  \"fields\": [\n    {\n      \"column\": \"OBJECTID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2891,\n        \"min\": 3,\n        \"max\": 9771,\n        \"num_unique_values\": 2393,\n        \"samples\": [\n          1465,\n          611,\n          6093\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"osm_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 351795408,\n        \"min\": 2682663,\n        \"max\": 1214584772,\n        \"num_unique_values\": 1597,\n        \"samples\": [\n          864044053,\n          122254566,\n          377069770\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"osm_id_final\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2393,\n        \"samples\": [\n          \"253360475_1\",\n          \"122254552_1\",\n          \"930680541_5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Start_Lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016538486193851686,\n        \"min\": 7.6792223,\n        \"max\": 7.7514665,\n        \"num_unique_values\": 2372,\n        \"samples\": [\n          7.6895506,\n          7.7021214,\n          7.703937\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Start_Lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010088189153522067,\n        \"min\": 45.0816207,\n        \"max\": 45.1326893,\n        \"num_unique_values\": 2373,\n        \"samples\": [\n          45.096412,\n          45.0902292,\n          45.0910466\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"End_Lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016547101717426575,\n        \"min\": 7.6792223,\n        \"max\": 7.7513792,\n        \"num_unique_values\": 2377,\n        \"samples\": [\n          7.691574,\n          7.6959849,\n          7.7036529\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"End_Lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01008457790754598,\n        \"min\": 45.0817578,\n        \"max\": 45.1327291,\n        \"num_unique_values\": 2376,\n        \"samples\": [\n          45.0920387,\n          45.1006208,\n          45.0910215\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Center_Lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01654239850839751,\n        \"min\": 7.67930575,\n        \"max\": 7.75137065,\n        \"num_unique_values\": 2388,\n        \"samples\": [\n          7.71601375,\n          7.7050461,\n          7.699985\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Center_Lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010085935408760871,\n        \"min\": 45.08168925,\n        \"max\": 45.1327092,\n        \"num_unique_values\": 2389,\n        \"samples\": [\n          45.1040663,\n          45.1013734,\n          45.12566125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LINE_LENGTH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.451353169687142,\n        \"min\": 3.233110875917183,\n        \"max\": 205.3075767613165,\n        \"num_unique_values\": 2393,\n        \"samples\": [\n          16.18864303297324,\n          21.24083196364763,\n          9.618401291174575\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LINE_BEARING\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 102.87778362233206,\n        \"min\": 0.0,\n        \"max\": 359.9431621745194,\n        \"num_unique_values\": 2379,\n        \"samples\": [\n          206.7966410390359,\n          86.06824439871693,\n          91.12745453661883\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"st_facing_manual\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "frontlines_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-44fb5c12-0092-4fa2-b4dd-e5530aeac95d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>osm_id</th>\n",
       "      <th>osm_id_final</th>\n",
       "      <th>Start_Lon</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>End_Lon</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>Center_Lon</th>\n",
       "      <th>Center_Lat</th>\n",
       "      <th>LINE_LENGTH</th>\n",
       "      <th>LINE_BEARING</th>\n",
       "      <th>st_facing_manual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>83471230</td>\n",
       "      <td>83471230_3</td>\n",
       "      <td>7.706208</td>\n",
       "      <td>45.096171</td>\n",
       "      <td>7.706241</td>\n",
       "      <td>45.096734</td>\n",
       "      <td>7.706225</td>\n",
       "      <td>45.096452</td>\n",
       "      <td>62.635242</td>\n",
       "      <td>2.411950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>83471233</td>\n",
       "      <td>83471233_1</td>\n",
       "      <td>7.705838</td>\n",
       "      <td>45.097673</td>\n",
       "      <td>7.705801</td>\n",
       "      <td>45.097166</td>\n",
       "      <td>7.705819</td>\n",
       "      <td>45.097419</td>\n",
       "      <td>56.362096</td>\n",
       "      <td>182.904191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>83471234</td>\n",
       "      <td>83471234_3</td>\n",
       "      <td>7.703627</td>\n",
       "      <td>45.097317</td>\n",
       "      <td>7.703663</td>\n",
       "      <td>45.097824</td>\n",
       "      <td>7.703645</td>\n",
       "      <td>45.097571</td>\n",
       "      <td>56.373605</td>\n",
       "      <td>2.911479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>83471237</td>\n",
       "      <td>83471237_3</td>\n",
       "      <td>7.707488</td>\n",
       "      <td>45.095631</td>\n",
       "      <td>7.707522</td>\n",
       "      <td>45.096194</td>\n",
       "      <td>7.707505</td>\n",
       "      <td>45.095913</td>\n",
       "      <td>62.635197</td>\n",
       "      <td>2.412039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>83471238</td>\n",
       "      <td>83471238_1</td>\n",
       "      <td>7.705814</td>\n",
       "      <td>45.096960</td>\n",
       "      <td>7.705768</td>\n",
       "      <td>45.096427</td>\n",
       "      <td>7.705791</td>\n",
       "      <td>45.096694</td>\n",
       "      <td>59.357366</td>\n",
       "      <td>183.508419</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>9757</td>\n",
       "      <td>1214584770</td>\n",
       "      <td>1214584770_2</td>\n",
       "      <td>7.697674</td>\n",
       "      <td>45.105997</td>\n",
       "      <td>7.697440</td>\n",
       "      <td>45.106057</td>\n",
       "      <td>7.697557</td>\n",
       "      <td>45.106027</td>\n",
       "      <td>19.549598</td>\n",
       "      <td>290.143764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>9762</td>\n",
       "      <td>1214584771</td>\n",
       "      <td>1214584771_3</td>\n",
       "      <td>7.698083</td>\n",
       "      <td>45.106000</td>\n",
       "      <td>7.698037</td>\n",
       "      <td>45.105940</td>\n",
       "      <td>7.698060</td>\n",
       "      <td>45.105970</td>\n",
       "      <td>7.622774</td>\n",
       "      <td>208.206956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>9763</td>\n",
       "      <td>1214584771</td>\n",
       "      <td>1214584771_4</td>\n",
       "      <td>7.698037</td>\n",
       "      <td>45.105940</td>\n",
       "      <td>7.697752</td>\n",
       "      <td>45.106041</td>\n",
       "      <td>7.697895</td>\n",
       "      <td>45.105990</td>\n",
       "      <td>25.095010</td>\n",
       "      <td>296.561084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>9768</td>\n",
       "      <td>1214584772</td>\n",
       "      <td>1214584772_1</td>\n",
       "      <td>7.698279</td>\n",
       "      <td>45.106267</td>\n",
       "      <td>7.698200</td>\n",
       "      <td>45.106145</td>\n",
       "      <td>7.698239</td>\n",
       "      <td>45.106206</td>\n",
       "      <td>14.912131</td>\n",
       "      <td>204.734596</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>9771</td>\n",
       "      <td>1214584772</td>\n",
       "      <td>1214584772_4</td>\n",
       "      <td>7.698073</td>\n",
       "      <td>45.106321</td>\n",
       "      <td>7.698279</td>\n",
       "      <td>45.106267</td>\n",
       "      <td>7.698176</td>\n",
       "      <td>45.106294</td>\n",
       "      <td>17.299046</td>\n",
       "      <td>110.479065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2393 rows × 12 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44fb5c12-0092-4fa2-b4dd-e5530aeac95d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-44fb5c12-0092-4fa2-b4dd-e5530aeac95d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-44fb5c12-0092-4fa2-b4dd-e5530aeac95d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-637e5785-1127-4ffe-af9a-a7670cee6f37\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-637e5785-1127-4ffe-af9a-a7670cee6f37')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-637e5785-1127-4ffe-af9a-a7670cee6f37 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_957439b5-1206-44a5-867c-790d561e41c8\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('frontlines_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_957439b5-1206-44a5-867c-790d561e41c8 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('frontlines_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      OBJECTID      osm_id  osm_id_final  Start_Lon  Start_Lat   End_Lon  \\\n",
       "0            3    83471230    83471230_3   7.706208  45.096171  7.706241   \n",
       "1            5    83471233    83471233_1   7.705838  45.097673  7.705801   \n",
       "2           11    83471234    83471234_3   7.703627  45.097317  7.703663   \n",
       "3           15    83471237    83471237_3   7.707488  45.095631  7.707522   \n",
       "4           17    83471238    83471238_1   7.705814  45.096960  7.705768   \n",
       "...        ...         ...           ...        ...        ...       ...   \n",
       "2388      9757  1214584770  1214584770_2   7.697674  45.105997  7.697440   \n",
       "2389      9762  1214584771  1214584771_3   7.698083  45.106000  7.698037   \n",
       "2390      9763  1214584771  1214584771_4   7.698037  45.105940  7.697752   \n",
       "2391      9768  1214584772  1214584772_1   7.698279  45.106267  7.698200   \n",
       "2392      9771  1214584772  1214584772_4   7.698073  45.106321  7.698279   \n",
       "\n",
       "        End_Lat  Center_Lon  Center_Lat  LINE_LENGTH  LINE_BEARING  \\\n",
       "0     45.096734    7.706225   45.096452    62.635242      2.411950   \n",
       "1     45.097166    7.705819   45.097419    56.362096    182.904191   \n",
       "2     45.097824    7.703645   45.097571    56.373605      2.911479   \n",
       "3     45.096194    7.707505   45.095913    62.635197      2.412039   \n",
       "4     45.096427    7.705791   45.096694    59.357366    183.508419   \n",
       "...         ...         ...         ...          ...           ...   \n",
       "2388  45.106057    7.697557   45.106027    19.549598    290.143764   \n",
       "2389  45.105940    7.698060   45.105970     7.622774    208.206956   \n",
       "2390  45.106041    7.697895   45.105990    25.095010    296.561084   \n",
       "2391  45.106145    7.698239   45.106206    14.912131    204.734596   \n",
       "2392  45.106267    7.698176   45.106294    17.299046    110.479065   \n",
       "\n",
       "      st_facing_manual  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  \n",
       "...                ...  \n",
       "2388                 1  \n",
       "2389                 1  \n",
       "2390                 1  \n",
       "2391                 1  \n",
       "2392                 1  \n",
       "\n",
       "[2393 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load frontlines_df, the file from GIS containing all building polygons split into line segments\n",
    "# and filtered to include only street-facing line segments.\n",
    "\n",
    "frontlines_df = pd.read_excel(DATA_FOLDER+'frontlines_for_extraction.xlsx')\n",
    "frontlines_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B5PE4CzVB7mF"
   },
   "outputs": [],
   "source": [
    "# # # ONLY USE THIS CELL IF UNIQUE IDENTIFIERS NOT YET CREATED ('osm_id_final' and 'image_id')\n",
    "\n",
    "# # # Make unique identifier for each line segment in building.\n",
    "# frontlines_df['osm_id_final'] = frontlines_df.groupby('osm_id').cumcount().add(1).astype(str)\n",
    "# frontlines_df['osm_id_final'] = frontlines_df['osm_id'].astype(str) + '_' + frontlines_df['osm_id_final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 158,
     "status": "ok",
     "timestamp": 1745425934347,
     "user": {
      "displayName": "Anthony Suppa",
      "userId": "01433471648786880681"
     },
     "user_tz": -120
    },
    "id": "RnprLEg0gYAm",
    "outputId": "cd1d5e1d-76ad-4883-81a0-9104715a00be"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"frontlines_df\",\n  \"rows\": 2393,\n  \"fields\": [\n    {\n      \"column\": \"OBJECTID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2891,\n        \"min\": 3,\n        \"max\": 9771,\n        \"num_unique_values\": 2393,\n        \"samples\": [\n          1465,\n          611,\n          6093\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"osm_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 351795408,\n        \"min\": 2682663,\n        \"max\": 1214584772,\n        \"num_unique_values\": 1597,\n        \"samples\": [\n          864044053,\n          122254566,\n          377069770\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"osm_id_final\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2393,\n        \"samples\": [\n          \"253360475_1\",\n          \"122254552_1\",\n          \"930680541_5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Start_Lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016538486193851686,\n        \"min\": 7.6792223,\n        \"max\": 7.7514665,\n        \"num_unique_values\": 2372,\n        \"samples\": [\n          7.6895506,\n          7.7021214,\n          7.703937\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Start_Lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010088189153522067,\n        \"min\": 45.0816207,\n        \"max\": 45.1326893,\n        \"num_unique_values\": 2373,\n        \"samples\": [\n          45.096412,\n          45.0902292,\n          45.0910466\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"End_Lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016547101717426575,\n        \"min\": 7.6792223,\n        \"max\": 7.7513792,\n        \"num_unique_values\": 2377,\n        \"samples\": [\n          7.691574,\n          7.6959849,\n          7.7036529\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"End_Lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01008457790754598,\n        \"min\": 45.0817578,\n        \"max\": 45.1327291,\n        \"num_unique_values\": 2376,\n        \"samples\": [\n          45.0920387,\n          45.1006208,\n          45.0910215\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Center_Lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01654239850839751,\n        \"min\": 7.67930575,\n        \"max\": 7.75137065,\n        \"num_unique_values\": 2388,\n        \"samples\": [\n          7.71601375,\n          7.7050461,\n          7.699985\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Center_Lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010085935408760871,\n        \"min\": 45.08168925,\n        \"max\": 45.1327092,\n        \"num_unique_values\": 2389,\n        \"samples\": [\n          45.1040663,\n          45.1013734,\n          45.12566125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LINE_LENGTH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.451353169687142,\n        \"min\": 3.233110875917183,\n        \"max\": 205.3075767613165,\n        \"num_unique_values\": 2393,\n        \"samples\": [\n          16.18864303297324,\n          21.24083196364763,\n          9.618401291174575\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LINE_BEARING\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 102.87778362233206,\n        \"min\": 0.0,\n        \"max\": 359.9431621745194,\n        \"num_unique_values\": 2379,\n        \"samples\": [\n          206.7966410390359,\n          86.06824439871693,\n          91.12745453661883\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"st_facing_manual\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2393,\n        \"samples\": [\n          \"253360475_1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"perp_angle\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105.84409403744489,\n        \"min\": 0.5535614708965113,\n        \"max\": 360.0,\n        \"num_unique_values\": 2379,\n        \"samples\": [\n          296.7966410390359\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "frontlines_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-82d19ac1-aa44-4ece-ba6a-93693d0843fa\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>osm_id</th>\n",
       "      <th>osm_id_final</th>\n",
       "      <th>Start_Lon</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>End_Lon</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>Center_Lon</th>\n",
       "      <th>Center_Lat</th>\n",
       "      <th>LINE_LENGTH</th>\n",
       "      <th>LINE_BEARING</th>\n",
       "      <th>st_facing_manual</th>\n",
       "      <th>image_id</th>\n",
       "      <th>perp_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>83471230</td>\n",
       "      <td>83471230_3</td>\n",
       "      <td>7.706208</td>\n",
       "      <td>45.096171</td>\n",
       "      <td>7.706241</td>\n",
       "      <td>45.096734</td>\n",
       "      <td>7.706225</td>\n",
       "      <td>45.096452</td>\n",
       "      <td>62.635242</td>\n",
       "      <td>2.411950</td>\n",
       "      <td>1</td>\n",
       "      <td>83471230_3</td>\n",
       "      <td>92.411950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>83471233</td>\n",
       "      <td>83471233_1</td>\n",
       "      <td>7.705838</td>\n",
       "      <td>45.097673</td>\n",
       "      <td>7.705801</td>\n",
       "      <td>45.097166</td>\n",
       "      <td>7.705819</td>\n",
       "      <td>45.097419</td>\n",
       "      <td>56.362096</td>\n",
       "      <td>182.904191</td>\n",
       "      <td>1</td>\n",
       "      <td>83471233_1</td>\n",
       "      <td>272.904191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>83471234</td>\n",
       "      <td>83471234_3</td>\n",
       "      <td>7.703627</td>\n",
       "      <td>45.097317</td>\n",
       "      <td>7.703663</td>\n",
       "      <td>45.097824</td>\n",
       "      <td>7.703645</td>\n",
       "      <td>45.097571</td>\n",
       "      <td>56.373605</td>\n",
       "      <td>2.911479</td>\n",
       "      <td>1</td>\n",
       "      <td>83471234_3</td>\n",
       "      <td>92.911479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>83471237</td>\n",
       "      <td>83471237_3</td>\n",
       "      <td>7.707488</td>\n",
       "      <td>45.095631</td>\n",
       "      <td>7.707522</td>\n",
       "      <td>45.096194</td>\n",
       "      <td>7.707505</td>\n",
       "      <td>45.095913</td>\n",
       "      <td>62.635197</td>\n",
       "      <td>2.412039</td>\n",
       "      <td>1</td>\n",
       "      <td>83471237_3</td>\n",
       "      <td>92.412039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>83471238</td>\n",
       "      <td>83471238_1</td>\n",
       "      <td>7.705814</td>\n",
       "      <td>45.096960</td>\n",
       "      <td>7.705768</td>\n",
       "      <td>45.096427</td>\n",
       "      <td>7.705791</td>\n",
       "      <td>45.096694</td>\n",
       "      <td>59.357366</td>\n",
       "      <td>183.508419</td>\n",
       "      <td>1</td>\n",
       "      <td>83471238_1</td>\n",
       "      <td>273.508419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>9757</td>\n",
       "      <td>1214584770</td>\n",
       "      <td>1214584770_2</td>\n",
       "      <td>7.697674</td>\n",
       "      <td>45.105997</td>\n",
       "      <td>7.697440</td>\n",
       "      <td>45.106057</td>\n",
       "      <td>7.697557</td>\n",
       "      <td>45.106027</td>\n",
       "      <td>19.549598</td>\n",
       "      <td>290.143764</td>\n",
       "      <td>1</td>\n",
       "      <td>1214584770_2</td>\n",
       "      <td>20.143764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>9762</td>\n",
       "      <td>1214584771</td>\n",
       "      <td>1214584771_3</td>\n",
       "      <td>7.698083</td>\n",
       "      <td>45.106000</td>\n",
       "      <td>7.698037</td>\n",
       "      <td>45.105940</td>\n",
       "      <td>7.698060</td>\n",
       "      <td>45.105970</td>\n",
       "      <td>7.622774</td>\n",
       "      <td>208.206956</td>\n",
       "      <td>1</td>\n",
       "      <td>1214584771_3</td>\n",
       "      <td>298.206956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>9763</td>\n",
       "      <td>1214584771</td>\n",
       "      <td>1214584771_4</td>\n",
       "      <td>7.698037</td>\n",
       "      <td>45.105940</td>\n",
       "      <td>7.697752</td>\n",
       "      <td>45.106041</td>\n",
       "      <td>7.697895</td>\n",
       "      <td>45.105990</td>\n",
       "      <td>25.095010</td>\n",
       "      <td>296.561084</td>\n",
       "      <td>1</td>\n",
       "      <td>1214584771_4</td>\n",
       "      <td>26.561084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>9768</td>\n",
       "      <td>1214584772</td>\n",
       "      <td>1214584772_1</td>\n",
       "      <td>7.698279</td>\n",
       "      <td>45.106267</td>\n",
       "      <td>7.698200</td>\n",
       "      <td>45.106145</td>\n",
       "      <td>7.698239</td>\n",
       "      <td>45.106206</td>\n",
       "      <td>14.912131</td>\n",
       "      <td>204.734596</td>\n",
       "      <td>1</td>\n",
       "      <td>1214584772_1</td>\n",
       "      <td>294.734596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>9771</td>\n",
       "      <td>1214584772</td>\n",
       "      <td>1214584772_4</td>\n",
       "      <td>7.698073</td>\n",
       "      <td>45.106321</td>\n",
       "      <td>7.698279</td>\n",
       "      <td>45.106267</td>\n",
       "      <td>7.698176</td>\n",
       "      <td>45.106294</td>\n",
       "      <td>17.299046</td>\n",
       "      <td>110.479065</td>\n",
       "      <td>1</td>\n",
       "      <td>1214584772_4</td>\n",
       "      <td>200.479065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2393 rows × 14 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82d19ac1-aa44-4ece-ba6a-93693d0843fa')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-82d19ac1-aa44-4ece-ba6a-93693d0843fa button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-82d19ac1-aa44-4ece-ba6a-93693d0843fa');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-bf465c9c-abea-4cbd-8a6e-c45c41598a33\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf465c9c-abea-4cbd-8a6e-c45c41598a33')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-bf465c9c-abea-4cbd-8a6e-c45c41598a33 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_84b3422f-2745-45c8-993f-4c89eae2e201\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('frontlines_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_84b3422f-2745-45c8-993f-4c89eae2e201 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('frontlines_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      OBJECTID      osm_id  osm_id_final  Start_Lon  Start_Lat   End_Lon  \\\n",
       "0            3    83471230    83471230_3   7.706208  45.096171  7.706241   \n",
       "1            5    83471233    83471233_1   7.705838  45.097673  7.705801   \n",
       "2           11    83471234    83471234_3   7.703627  45.097317  7.703663   \n",
       "3           15    83471237    83471237_3   7.707488  45.095631  7.707522   \n",
       "4           17    83471238    83471238_1   7.705814  45.096960  7.705768   \n",
       "...        ...         ...           ...        ...        ...       ...   \n",
       "2388      9757  1214584770  1214584770_2   7.697674  45.105997  7.697440   \n",
       "2389      9762  1214584771  1214584771_3   7.698083  45.106000  7.698037   \n",
       "2390      9763  1214584771  1214584771_4   7.698037  45.105940  7.697752   \n",
       "2391      9768  1214584772  1214584772_1   7.698279  45.106267  7.698200   \n",
       "2392      9771  1214584772  1214584772_4   7.698073  45.106321  7.698279   \n",
       "\n",
       "        End_Lat  Center_Lon  Center_Lat  LINE_LENGTH  LINE_BEARING  \\\n",
       "0     45.096734    7.706225   45.096452    62.635242      2.411950   \n",
       "1     45.097166    7.705819   45.097419    56.362096    182.904191   \n",
       "2     45.097824    7.703645   45.097571    56.373605      2.911479   \n",
       "3     45.096194    7.707505   45.095913    62.635197      2.412039   \n",
       "4     45.096427    7.705791   45.096694    59.357366    183.508419   \n",
       "...         ...         ...         ...          ...           ...   \n",
       "2388  45.106057    7.697557   45.106027    19.549598    290.143764   \n",
       "2389  45.105940    7.698060   45.105970     7.622774    208.206956   \n",
       "2390  45.106041    7.697895   45.105990    25.095010    296.561084   \n",
       "2391  45.106145    7.698239   45.106206    14.912131    204.734596   \n",
       "2392  45.106267    7.698176   45.106294    17.299046    110.479065   \n",
       "\n",
       "      st_facing_manual      image_id  perp_angle  \n",
       "0                    1    83471230_3   92.411950  \n",
       "1                    1    83471233_1  272.904191  \n",
       "2                    1    83471234_3   92.911479  \n",
       "3                    1    83471237_3   92.412039  \n",
       "4                    1    83471238_1  273.508419  \n",
       "...                ...           ...         ...  \n",
       "2388                 1  1214584770_2   20.143764  \n",
       "2389                 1  1214584771_3  298.206956  \n",
       "2390                 1  1214584771_4   26.561084  \n",
       "2391                 1  1214584772_1  294.734596  \n",
       "2392                 1  1214584772_4  200.479065  \n",
       "\n",
       "[2393 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The field 'image_id' can be set to equal 'osm_id_final', unless the user\n",
    "# has another image_id naming scheme.\n",
    "# There could be a difference between image_id and osm_id_final if extracted\n",
    "# images eventually get split (e.g. \"_left\" or \"_right\") during image review stages.\n",
    "frontlines_df['image_id'] = frontlines_df['osm_id_final']\n",
    "\n",
    "# If not done already, add the perpendicular angle, i.e. from a GSV camera towards\n",
    "# a street_facing front. In ArcGIS, this is consistently the bearing of the line plus 90 degrees.\n",
    "frontlines_df['perp_angle'] = frontlines_df['LINE_BEARING'] + 90\n",
    "frontlines_df['perp_angle'] = frontlines_df['perp_angle'].apply(lambda x: x - 360 if x > 360 else x)\n",
    "frontlines_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7PZpY9JsuI3"
   },
   "outputs": [],
   "source": [
    "# Once complete, save the unique identifiers, also import to GIS so that only these\n",
    "# unique identifiers are used for the line segments.\n",
    "export_dir = # directory to save dataframe\n",
    "export_fname = # file name to save + .xlsx'\n",
    "frontlines_df.to_excel(os.path.join(export_dir,export_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujmgTtXPhbC9"
   },
   "source": [
    "# Set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhmsYjaP30N_"
   },
   "outputs": [],
   "source": [
    "# API key for GSV\n",
    "KEY = # INSERT API KEY HERE\n",
    "\n",
    "FOV = 120 # Field of view to use when capturing GSV images, default is 120 degrees.\n",
    "RADIUS = 20 # Radius to search for GSV camera within given coordinates, default is 20 meters.\n",
    "PITCH_LST = [90, 110] # List of pitches to use when capturing GSV images.\n",
    "                      # 90 degrees is horizontal; 110 degrees is the default second pitch\n",
    "                      # to capture upper view of buildings.\n",
    "ROTATION_CORRECTION = 0 # Correction, in degrees, added to rotation from perpendicular angle with\n",
    "                        # rotation_one_camera function.\n",
    "                        # Only used if the user wants to capture slightly wider extents than calculated by script.\n",
    "                        # Default is zero.\n",
    "\n",
    "# The main folder is where constituent image tiles are saved,\n",
    "# give it a suitable project name. The date is automatcially appended.\n",
    "MAIN_NAME = # ADD A FOLDER NAME WHERE IMAGES ARE SAVED, e.g. based on project title\n",
    "MAIN_FOLDER = datetime.today().strftime('%Y-%m-%d') + '_' + MAIN_NAME # Data automatically added\n",
    "print('main folder: ', MAIN_FOLDER)\n",
    "\n",
    "# The stitch folder is where final stitched images are saved,\n",
    "# add a suitable name.\n",
    "STITCH_NAME = 'Stitched'\n",
    "STITCH_FOLDER = os.path.join(MAIN_FOLDER,STITCH_NAME)\n",
    "print('stitch folder: ', STITCH_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wrK6YeYhWLV"
   },
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBNeOSXCuWoG"
   },
   "outputs": [],
   "source": [
    "def parse_dataframe(row, dataframe):\n",
    "  \"\"\"\n",
    "  Returns variables from dataframe for use in for loop, when running image extraction script\n",
    "\n",
    "  Arguments:\n",
    "  dataframe             --  pd.DataFrame; must contain columns \"image_id\", \"Center_Lon\", \"Center_Lat\", \"Start_Lon\",\n",
    "                            \"Start_Lat\", \"End_Lon\", \"End_Lat\", and \"LINE_BEARING\".\n",
    "  row                   --  int; row number in dataframe.\n",
    "\n",
    "  Returns:\n",
    "  image_id              --  string; unique image identifier.\n",
    "  id_folder             --  string; folder name, where constituent images will be saved within MAIN_FOLDER.\n",
    "  center_lon            --  float; the longitude coordinate of the central point of the street-facing line segment.\n",
    "  center_lat            --  float; the latitude coordinate of the central point of the street-facing line segment.\n",
    "  corner_a_tup          --  tuple; the starting points (longitude, latitude) of the street-facing line segment.\n",
    "  corner_b_tup          --  tuple; the ending points (longitude, latitude) of the street-facing line segment.\n",
    "  perpendicular_angle   --  float; angle that is perpendicular to the facade to be captured.\n",
    "  \"\"\"\n",
    "  # extract paramaters from dataframe and set variables for each building id\n",
    "  image_id = dataframe.at[row,\"image_id\"]\n",
    "  id_folder = os.path.join(MAIN_FOLDER,str(image_id))\n",
    "\n",
    "  center_lon = dataframe.at[row,\"Center_Lon\"]\n",
    "  center_lat = dataframe.at[row,\"Center_Lat\"]\n",
    "  # center_string = str(center_lat)+','+str(center_lon)\n",
    "\n",
    "  corner_a_lon = dataframe.at[row,\"Start_Lon\"]\n",
    "  corner_a_lat = dataframe.at[row,\"Start_Lat\"]\n",
    "  corner_a_tup = (corner_a_lon, corner_a_lat)\n",
    "\n",
    "  corner_b_lon = dataframe.at[row,\"End_Lon\"]\n",
    "  corner_b_lat = dataframe.at[row,\"End_Lat\"]\n",
    "  corner_b_tup = (corner_b_lon, corner_b_lat)\n",
    "\n",
    "  line_bearing = dataframe.at[row,\"LINE_BEARING\"]\n",
    "  perpendicular_angle = dataframe.at[row,\"perp_angle\"]\n",
    "\n",
    "  return image_id, id_folder, center_lon, center_lat, corner_a_tup, corner_b_tup, perpendicular_angle\n",
    "\n",
    "\n",
    "def calculate_ctr_offset(perpendicular_angle, center_lon, center_lat, offset_dist=6):\n",
    "  \"\"\"\n",
    "  Function to calculate an offset from center of building facade, in direction that is\n",
    "  opposite the perpendicular_angle. This is a rough estimate of the GSV camera location\n",
    "  which helps avoid \"wrong camera\" errors when a facade is near two streets, i.e. a corner.\n",
    "\n",
    "  Arguments:\n",
    "  perpendicular_angle  --  float; angle that is perpendicular to the facade to be captured.\n",
    "  center_lon           --  float; longitude coordinate of central point of street-facing line segment.\n",
    "  center_lat           --  float; latitude coordinate of central point of street-facing line segment.\n",
    "  offset_dist          --  float; distance to offset from center of building facade.\n",
    "\n",
    "  Returns:\n",
    "  offset_coords        --  string; coordinates of offset location.\n",
    "  \"\"\"\n",
    "  offset_angle = perpendicular_angle - 180\n",
    "  offset_lon, offset_lat, _ = gd.fwd(center_lon, center_lat, offset_angle, offset_dist)\n",
    "  offset_coords = str(offset_lat)+','+str(offset_lon)\n",
    "  return offset_coords\n",
    "\n",
    "\n",
    "def get_center_camera(perpendicular_angle, fov, center_lon, center_lat, save_folder, radius=20, offset_dist=6):\n",
    "  \"\"\"\n",
    "  Functions to call GSV API to get central camera location by capturing one initial image\n",
    "  of the facade at the perpendicular angle, which also returns metadata containing the camera coordinates\n",
    "\n",
    "  Arguments:\n",
    "  perpendicular_angle   --  float; angle that is perpendicular to the facade to be captured.\n",
    "  fov                   --  int; the field of view requested from the GSV API.\n",
    "  center_lon            --  float; longitude coordinate of central point of street-facing line segment.\n",
    "  center_lat            --  float; latitude coordinate of central point of street-facing line segment.\n",
    "  save_folder           --  string; the folder where the image and metadata are to be saved.\n",
    "  radius                --  int; the maximum distance, in meters, from the specified center_lon and center_lat\n",
    "                            to look for the nearest GSV camera.\n",
    "  offset_dist           --  float; distance, in meters, to offset from center of building facade.\n",
    "\n",
    "  Returns:\n",
    "  camera_lon            --  float; longitude coordinate of the nearest GSV camera.\n",
    "  camera_lat            --  float; latitude coordinate of the nearest GSV camera.\n",
    "  img0                  --  numpy array image; this is the orthogonal view of the facade, which will be used\n",
    "                            in subsequent steps as the initial image to which all others will be stitched to.\n",
    "  \"\"\"\n",
    "  # estimate camera coordinates\n",
    "  estd_camera_coords = calculate_ctr_offset(perpendicular_angle, center_lon, center_lat, offset_dist)\n",
    "\n",
    "  params = [{\n",
    "         'size': '640x640', # max size is 640x640 pixels\n",
    "         'location': estd_camera_coords,\n",
    "         'fov' : fov,\n",
    "         'heading': perpendicular_angle,\n",
    "         'pitch': 0,\n",
    "         'radius' : radius, # try looking for camera within 20 meters of target location\n",
    "         'return_error_code' : True,\n",
    "         'source' : 'outdoor',\n",
    "         'key': KEY\n",
    "          }]\n",
    "  print(params)\n",
    "\n",
    "  # Create a results object from GSV API\n",
    "  results = google_streetview.api.results(params)\n",
    "  # Download images to save_folder\n",
    "  results.download_links(os.path.join(save_folder, 'initial_camera_0'))\n",
    "  sub_folder = os.path.join(save_folder, 'initial_camera_0')\n",
    "\n",
    "  # read image location if json file shows there was no error in retreiving image\n",
    "  json_file = os.path.join(sub_folder, 'metadata.json')\n",
    "  with open(json_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    status = data[0][\"status\"]\n",
    "    if status == \"NOT_FOUND\" or status == \"ZERO_RESULTS\":\n",
    "      return False, False, False\n",
    "    camera_pos_dict = data[0][\"location\"]\n",
    "    f.close\n",
    "  camera_pos = str(camera_pos_dict['lat']) + ',' + str(camera_pos_dict['lng'])\n",
    "  camera_lon = camera_pos_dict['lng']\n",
    "  camera_lat = camera_pos_dict['lat']\n",
    "\n",
    "  # img0 is the orthogonal view of the building facade\n",
    "  img0_path = save_folder + '/initial_camera_0/' +'gsv_0.jpg'\n",
    "  img0 = cv2.imread(img0_path, cv2.IMREAD_COLOR)\n",
    "  img0 = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)\n",
    "  return camera_lon, camera_lat, img0\n",
    "\n",
    "def calculate_point_d(point1, point2, point_c):\n",
    "  \"\"\"\n",
    "  Finds the point falling on the line between building corner 1 and 2.\n",
    "  The GSV camera (point C) forms a line with point D which is perpendicular to the line from corner 1 to 2.\n",
    "  This is used within the rotation_one_camera function.\n",
    "\n",
    "  Arguments:\n",
    "  point1   --  numpy array; vector of [longitude, latitude] of building corner 1\n",
    "  point2   --  numpy array; vector of [longitude, latitude] of building corner 2\n",
    "  point_c   --  numpy array; vector of [longitude, latitude] of GSV camera\n",
    "\n",
    "  Returns:\n",
    "  point_d   --  numpy array; vector of [longitude, latitude] where the perpendicular angle from\n",
    "                point_c meets line from corner 1 to 2.\n",
    "  \"\"\"\n",
    "  # Calculate the vector from point1 to point2\n",
    "  vector_p1_p2 = point2 - point1\n",
    "\n",
    "  # Calculate the vector from point1 to point_c\n",
    "  vector_p1_pc = point_c - point1\n",
    "\n",
    "  # Calculate the projection of vector_p1_pc onto vector_p1_p2\n",
    "  t = np.dot(vector_p1_pc, vector_p1_p2) / np.dot(vector_p1_p2, vector_p1_p2)\n",
    "\n",
    "  # Calculate the coordinates of point_d\n",
    "  point_d = point1 + t * vector_p1_p2\n",
    "\n",
    "  return point_d\n",
    "\n",
    "def rotation_one_camera(camera_lon, camera_lat, corner_a_lon, corner_a_lat,\n",
    "                        corner_b_lon, corner_b_lat, perpendicular_angle, fov, correction_factor=0):\n",
    "  \"\"\"\n",
    "  Calculates azimuth from central camera to corner points of buildng with PyProj library.\n",
    "  If the full building is not within the current field of view, the function calculates\n",
    "  the rotation required to capture additional images left/right to view the corners of the building.\n",
    "\n",
    "  Arguments:\n",
    "  camera_lon          --  float; longitude of the camera position from GSV, read in from metadata file.\n",
    "  camera_lat          --  float; latitude of the camera position from GSV, read in from metadata file.\n",
    "  corner_a_lon        --  float; the longitude of corner_a, read in from csv file and passed into a global variable.\n",
    "  corner_a_lat        --  float; the latitude of corner_a, read in from csv file and passed into a global variable.\n",
    "  corner_b_lon        --  float; the longitude of corner_b, read in from csv file and passed into a global variable.\n",
    "  corner_b_lat        --  float; the latitude of corner_b, read in from csv file and passed into a global variable.\n",
    "  perpendicular_angle --  float; angle that is perpendicular to the facade to be captured.\n",
    "  correction_factor   --  a number of degrees to add to the calculated camera rotation, in the event of consistent\n",
    "                          discrepancies in coordinates between OpenStreetMap (the source data) and GSV.\n",
    "\n",
    "  Returns:\n",
    "  capture_1           --  boolean; value indicating whether a new photograph should be captured towards corner_1,\n",
    "                          which is defined within the function as the building corner closer to field of view 1 (fov_1).\n",
    "  capture_2           --  boolean; value indicating whether a new photograph should be captured towards corner_2,\n",
    "                          which is defined within the function as the building corner closer to field of view 2 (fov_2).\n",
    "  heading_1           --  a heading in degrees to photograph corner_1.\n",
    "  heading_2           --  a heading in degrees to photograph corner_2.\n",
    "  \"\"\"\n",
    "\n",
    "  # Define the angles from the central camera defining the Field of View (fov)\n",
    "  fov_1 = (perpendicular_angle - fov/2)\n",
    "  fov_2 = (perpendicular_angle + fov/2)\n",
    "  if fov_2 > 360:\n",
    "    fov_2 -= 360\n",
    "\n",
    "  # Input points as vectors\n",
    "  camera_vec = np.array([camera_lon, camera_lat, 0])\n",
    "  corner_a_vec = np.array([corner_a_lon, corner_a_lat, 0])\n",
    "  corner_b_vec = np.array([corner_b_lon, corner_b_lat, 0])\n",
    "\n",
    "  # Find the point on the line between corner 1 and 2 where a perpendicular line\n",
    "  # from the camera falls. Find distance from this point to corners.\n",
    "  perp_point_vec = calculate_point_d(corner_a_vec, corner_b_vec, camera_vec)\n",
    "\n",
    "  # Calculate cross product to determine which of corner_a or _b is on the left\n",
    "  # of the photograph --> lower cross-product value goes to the left side\n",
    "  corner_a_cross = np.cross(corner_a_vec - camera_vec, perp_point_vec - camera_vec)[2]\n",
    "  corner_b_cross = np.cross(corner_b_vec - camera_vec, perp_point_vec - camera_vec)[2]\n",
    "\n",
    "  if corner_b_cross < corner_a_cross:\n",
    "    corner_1_lon, corner_1_lat = corner_b_lon, corner_b_lat\n",
    "    corner_2_lon, corner_2_lat = corner_a_lon, corner_a_lat\n",
    "  else:\n",
    "    corner_1_lon, corner_1_lat = corner_a_lon, corner_a_lat\n",
    "    corner_2_lon, corner_2_lat = corner_b_lon, corner_b_lat\n",
    "\n",
    "  fwd_azimuth_1, _, _ = gd.inv(camera_lon, camera_lat, corner_1_lon, corner_1_lat)\n",
    "  fwd_azimuth_2, _, _ = gd.inv(camera_lon, camera_lat, corner_2_lon, corner_2_lat)\n",
    "\n",
    "  # Adjust fwd_azimuth_1 and _2 to work for 0-360 degree plane with North at 0 degrees\n",
    "  if fov_1 > 0 and fwd_azimuth_1 < 0:\n",
    "    fwd_azimuth_1 += 360\n",
    "  if fwd_azimuth_2 < 0:\n",
    "    fwd_azimuth_2 += 360\n",
    "\n",
    "  # Determine if the angle to corner_1 (i.e. fwd_azimuth_1) is within fov_1\n",
    "  # If so, set capture_1 to True\n",
    "  if fwd_azimuth_1 >= fov_1:\n",
    "      capture_1 = False # i.e. don't need to capture a new photo toward this corner\n",
    "  elif (fov_2-fov) < fwd_azimuth_1 <= fov_2:\n",
    "      capture_1 = False\n",
    "  else:\n",
    "      capture_1 = True\n",
    "      rotation_1 = - np.abs(fov_1 - fwd_azimuth_1)\n",
    "\n",
    "  # If capture_1 is True, format the angles from 0 to 360 degrees and set the\n",
    "  # heading angle to be captured.\n",
    "  if capture_1 == True:\n",
    "    if rotation_1 < -360:\n",
    "      rotation_1 += 360\n",
    "    rotation_1 -= correction_factor # increase rotation_1 by the correction_factor by rotating more left\n",
    "    heading_1 = perpendicular_angle + rotation_1 # rotation_1 is a negative number, heading_1 will rotate left of perpendicular\n",
    "    if heading_1 < 0: # GSV seems to work better when headings are inputted as positive\n",
    "      heading_1 += 360\n",
    "  # If capture_1 is False, a rotation toward heading_1 is not required\n",
    "  else:\n",
    "    heading_1 = False\n",
    "\n",
    "  # Determine if the angle to corner_2 (i.e. fwd_azimuth_2) is within fov_2\n",
    "  # If so, set capture_2 to True\n",
    "  if fwd_azimuth_2 <= fov_2:\n",
    "      capture_2 = False # i.e. don't need to capture a new photo toward this corner\n",
    "  elif fov_1 < fwd_azimuth_2 <= (fov_1+fov):\n",
    "      capture_2 = False\n",
    "  else:\n",
    "      capture_2 = True\n",
    "      rotation_2 = np.abs(fwd_azimuth_2 - fov_2)\n",
    "\n",
    "  # If capture_2 is True, format the angles from 0 to 360 degrees and set the\n",
    "  # heading angle to be captured.\n",
    "  if capture_2 == True:\n",
    "    rotation_2 += correction_factor # increase rotation_2 by the correction_factor by rotating more right\n",
    "    heading_2 = perpendicular_angle + rotation_2 #rotation_2 is a positive number, heading_2 will rotate right of perpendicular\n",
    "    if heading_2 < 0:\n",
    "      heading_2 += 360\n",
    "    if heading_2 > 360:\n",
    "      heading_2 -= 360\n",
    "  # If capture_1 is False, a rotation toward heading_1 is not required\n",
    "  else:\n",
    "    heading_2 = False\n",
    "\n",
    "  return heading_1, heading_2\n",
    "\n",
    "def parse_headings(perpendicular_angle, heading_1, heading_2):\n",
    "  \"\"\"\n",
    "  Function to parse heading_1 and heading_2 into a list to be sent to GSV API\n",
    "  to capture additional images towards corner_1 and corner_2.\n",
    "\n",
    "  Arguments:\n",
    "  perpendicular_angle --  float; angle that is perpendicular to the facade to be captured.\n",
    "  heading_1           --  float; a heading in degrees to capture image of corner_1.\n",
    "  heading_2           --  float; a heading in degrees to capture image of corner_2.\n",
    "\n",
    "  Returns:\n",
    "  heading_lst         --  list; a list of headings to be sent to GSV API.\n",
    "  \"\"\"\n",
    "  # parse headings from rotation_one_camera function to create heading_lst\n",
    "  # to send to GSV API to request photos\n",
    "  heading_lst = []\n",
    "  if heading_1 != False and heading_2 != False:\n",
    "    heading_lst = [perpendicular_angle,heading_1,heading_2]\n",
    "  elif heading_1 == False and heading_2 == False:\n",
    "    heading_lst = [perpendicular_angle]\n",
    "  elif heading_1 == False:\n",
    "    heading_lst = [perpendicular_angle,heading_2]\n",
    "  elif heading_2 == False:\n",
    "    heading_lst = [perpendicular_angle,heading_1]\n",
    "\n",
    "  return heading_lst\n",
    "\n",
    "def get_gsv_photos(ortho_img, save_folder, camera_lon, camera_lat, head_lst, pitch_lst, fov, key, radius=20):\n",
    "  \"\"\"\n",
    "  Calls GSV API to capture and download photos according to desired location, heading, and pitch.\n",
    "\n",
    "  Arguments:\n",
    "  ortho_img   --  numpy array image; this is the orthogonal view of the facade returned as img0 in a previous function\n",
    "                  used as the initial image to which all others will be stitched to.\n",
    "  save_folder --  string; the folder where the images and metadata are to be saved.\n",
    "  camera_lon  --  float; longitude coordinate of the camera position from GSV, read in from metadata file.\n",
    "  camera_lat  --  float; latitude coordinate of the camera position from GSV, read in from metadata file.\n",
    "  head_lst    --  list; list headings of images to be captured from the GSV camera, ranging 1 to 3 headings\n",
    "                  per camera location, where head_lst[0] is always the orthogonal image at the perpendicular angle.\n",
    "  pitch_lst   --  list; list of pitches (in degrees) to be captured from the GSV camera.\n",
    "  fov         --  int; the field of view to be used when capturing GSV photos.\n",
    "  key         --  string; the user's API key, issued by Google.\n",
    "  radius      --  int; number of meters that GSV should search for one of its cameras from a target location.\n",
    "\n",
    "  Returns:\n",
    "  img_lst     --  list; list of the downloaded images, each of which is a numpy array image.\n",
    "  \"\"\"\n",
    "  # initialize the img_lst with the orthogonal image at index [0]\n",
    "  img_lst = [ortho_img]\n",
    "  filepath_lst = []\n",
    "  photo_counter = 1\n",
    "  # set camera location with GSV required format\n",
    "  gsv_cam_location = str(camera_lat)+','+str(camera_lon)\n",
    "\n",
    "  # run loop to capture photos from one location to all headings in head_lst\n",
    "  for i in range(len(head_lst)):\n",
    "    heading = head_lst[i]\n",
    "\n",
    "    # create for loop based on photo pitches in pitch_lst\n",
    "    for j in range(len(pitch_lst)):\n",
    "      if i == 0 and j == 0: # in this case, we already have the photo from the 1st API call\n",
    "        continue\n",
    "      # set parameters for photo\n",
    "      params = [{\n",
    "            'size': '640x640', # max size is 640x640 pixels\n",
    "            'location': gsv_cam_location,\n",
    "            'fov' : fov,\n",
    "            'heading': heading,\n",
    "            'pitch': (pitch_lst[j]-90),\n",
    "            'radius' : radius,\n",
    "            'return_error_code' : True,\n",
    "            'source' : 'outdoor',\n",
    "            'key': KEY\n",
    "            }]\n",
    "\n",
    "      # create a results object from GSV API and download images to directory\n",
    "      results = google_streetview.api.results(params)\n",
    "      results.download_links(os.path.join(save_folder, 'camera' + str(i) + '/shot_' + str(photo_counter)))\n",
    "      sub_folder = os.path.join(save_folder, 'camera' + str(i) + '/shot_' + str(photo_counter))\n",
    "\n",
    "      # read image if json file shows there was no error in retreiving image\n",
    "      json_file = os.path.join(sub_folder, 'metadata.json')\n",
    "      with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        status = data[0][\"status\"]\n",
    "        if status == \"NOT_FOUND\" or status == \"ZERO_RESULTS\":\n",
    "          continue\n",
    "        f.close\n",
    "\n",
    "      # set file path, read images and save to image_lst\n",
    "      filepath = os.path.join(sub_folder, 'gsv_0.jpg')\n",
    "      filepath_lst.append(filepath)\n",
    "      img = cv2.imread(filepath, cv2.IMREAD_COLOR)\n",
    "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "      img_lst.append(img)\n",
    "\n",
    "      # increase photo_counter to have unique photo names\n",
    "      photo_counter += 1\n",
    "\n",
    "  return img_lst\n",
    "\n",
    "def stitch_it(img_src, img_target):\n",
    "  \"\"\"\n",
    "  Stitches two images together by computing homography, starting with the orthogonal image (img_src) at the bottom\n",
    "  and warping perspective of the second image (img_target) on top of this. Uses SIFT as feature detector.\n",
    "  This function is sed within stitch_two, stitch_four, and stitch_six functions, which add automatic column\n",
    "  or row cropping in between rounds of stitching.\n",
    "\n",
    "  Arguments:\n",
    "  img_src       --  numpy array image, color; source image to be read into numpy array from .jpg outside of function.\n",
    "                    This image must be orthogonal, i.e. taken at a heading perpendicular to the building, using a pitch of 90 degrees.\n",
    "  img_target    --  numpy array image, color; target image to be read into numpy array from .jpg outside of function.\n",
    "                    This image will be warped and stitched to the source image.\n",
    "\n",
    "  Returns:\n",
    "  stitched_img  --  numpy array image, color; the resulting stitched image\n",
    "  len(matches)  --  number of keypoint matches used to find homography, can be saved in logs in subsequent functions.\n",
    "  \"\"\"\n",
    "\n",
    "  #Convert images to grayscale to do feature detection\n",
    "  img_src_gray = cv2.cvtColor(img_src, cv2.COLOR_BGR2GRAY)\n",
    "  img_target_gray = cv2.cvtColor(img_target, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  # From: https://docs.opencv.org/3.4/d1/de0/tutorial_py_feature_homography.html\n",
    "  MIN_MATCH_COUNT = 10\n",
    "\n",
    "  # Detect SIFT features and compute descriptors\n",
    "  MAX_NUM_FEATURES = 500\n",
    "  sift = cv2.SIFT_create(MAX_NUM_FEATURES)\n",
    "  keypoints_src, descriptors_src = sift.detectAndCompute(img_src_gray, None)\n",
    "  keypoints_target, descriptors_target = sift.detectAndCompute(img_target_gray, None)\n",
    "\n",
    "  # Find nearest match with KNN algorithm\n",
    "  FLANN_INDEX_KDTREE = 1\n",
    "  index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "  search_params = dict(checks=50)\n",
    "\n",
    "  # Match features\n",
    "  flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "  matches = flann.knnMatch(descriptors_src, descriptors_target, k=2)\n",
    "\n",
    "  # Store all good matches as per Lowe's ratio test\n",
    "  good = []\n",
    "  for m, n in matches:\n",
    "    if m.distance < 0.7*n.distance:\n",
    "      good.append(m)\n",
    "  matches = good\n",
    "  print('no. good matches: ', len(matches))\n",
    "\n",
    "  # FIND HOMOGRAPHY\n",
    "  # Extract location of good matches\n",
    "  points_src = np.zeros((len(matches),2), dtype=np.float32)\n",
    "  points_target = np.zeros((len(matches),2), dtype=np.float32)\n",
    "\n",
    "  for idx0, match in enumerate(matches):\n",
    "    points_src[idx0, :] = keypoints_src[match.queryIdx].pt\n",
    "    points_target[idx0, :] = keypoints_target[match.trainIdx].pt\n",
    "\n",
    "  # Find homography\n",
    "  H, mask = cv2.findHomography(points_target, points_src, cv2.RANSAC)\n",
    "\n",
    "  # Use homography to warp image\n",
    "  # Adapted from:\n",
    "  # https://stackoverflow.com/questions/13063201/how-to-show-the-whole-image-when-using-opencv-warpperspective\n",
    "  h0,w0 = img_src.shape[:2]\n",
    "  h1,w1 = img_target.shape[:2]\n",
    "  pts0 = np.float32([[0,0],[0,h0],[w0,h0],[w0,0]]).reshape(-1,1,2)\n",
    "  pts1 = np.float32([[0,0],[0,h1],[w1,h1],[w1,0]]).reshape(-1,1,2)\n",
    "  pts1_ = cv2.perspectiveTransform(pts1, H)\n",
    "  pts = np.concatenate((pts0, pts1_), axis=0)\n",
    "  [xmin, ymin] = np.int32(pts.min(axis=0).ravel() - 0.5)\n",
    "  [xmax, ymax] = np.int32(pts.max(axis=0).ravel() + 0.5)\n",
    "  t = [-xmin,-ymin]\n",
    "  Ht = np.array([[1,0,t[0]],[0,1,t[1]],[0,0,1]]) # translate\n",
    "\n",
    "  stitched_img = cv2.warpPerspective(img_target, Ht.dot(H), (xmax-xmin, ymax-ymin), cv2.INTER_LINEAR, cv2.BORDER_REPLICATE)\n",
    "  stitched_img[t[1]:h0+t[1],t[0]:w0+t[0]] = img_src\n",
    "\n",
    "  return stitched_img, len(matches)\n",
    "\n",
    "def autocrop_col(img_src, crop_thresh=0.15):\n",
    "  \"\"\"\n",
    "  Automatically crops images when more than a crop threshold (default = 15%) of the COLUMN is black.\n",
    "  Used after FIRST round of image stitching.\n",
    "\n",
    "  Arguments:\n",
    "  img_src       --  numpy array image, color; source image to be cropped to where most of column\n",
    "                    (i.e. greater than crop threshold) is black.\n",
    "  crop_thresh   --  float; if more than this value (default = 15%) of the row is black, the column is cropped.\n",
    "\n",
    "\n",
    "  Returns:\n",
    "  img_crop      --  numpy array image, color; image cropped to where most of row (i.e. greater than threshold) is black.\n",
    "  \"\"\"\n",
    "  # convert to gray and threshold image\n",
    "  gray = cv2.cvtColor(img_src,cv2.COLOR_BGR2GRAY)\n",
    "  _,thresh = cv2.threshold(gray,1,255,cv2.THRESH_BINARY)\n",
    "  # the target is the value if all pixels in column times the crop threshold are white\n",
    "  target = 255 * (1 - crop_thresh) * thresh.shape[0]\n",
    "  # get the sum of values of each column, store in summmed array\n",
    "  summed = np.sum(thresh, axis=0)\n",
    "  # iterate through array, collect indexes where the value of a summed column is less than the target\n",
    "  for idx1 in range(summed.shape[0]):\n",
    "    if summed[idx1] < target:\n",
    "      thresh[:,idx1] = 0\n",
    "  # make bounding rectangle according to crop indexes and crop image\n",
    "  x,y,w,h = cv2.boundingRect(thresh)\n",
    "  img_crop = img_src[y:y+h,x:x+w]\n",
    "  return img_crop\n",
    "\n",
    "def autocrop_row(img_src, crop_thresh=0.15):\n",
    "  \"\"\"\n",
    "  Automatically crops images when more than a crop threshold (default = 15%) of the ROW is black.\n",
    "  Used after SECOND round of image stitching.\n",
    "\n",
    "  Arguments:\n",
    "  img_src       --  numpy array image, color; source image to be cropped to where most of row\n",
    "                    (i.e. greater than crop threshold) is black.\n",
    "  crop_thresh   --  float; if more than this value (default = 15%) of the row is black, the row is cropped.\n",
    "\n",
    "\n",
    "  Returns:\n",
    "  img_crop      --  numpy array image, color; image cropped to where most of row (i.e. greater than threshold) is black.\n",
    "  \"\"\"\n",
    "  # convert to gray and threshold image\n",
    "  gray = cv2.cvtColor(img_src,cv2.COLOR_BGR2GRAY)\n",
    "  _,thresh = cv2.threshold(gray,1,255,cv2.THRESH_BINARY)\n",
    "  # the target is the value if all pixels in row times the crop threshold are white\n",
    "  target = 255 * (1 - crop_thresh) * thresh.shape[1]\n",
    "  # get the sum of values of each row, store in summmed array\n",
    "  summed = np.sum(thresh, axis=1)\n",
    "  # iterate through array, collect indexes where the value of a summed row is less than the target\n",
    "  for idx2 in range(summed.shape[0]):\n",
    "    if summed[idx2] < target:\n",
    "      thresh[idx2,:] = 0\n",
    "  # make bounding rectangle according to crop indexes and crop image\n",
    "  x,y,w,h = cv2.boundingRect(thresh)\n",
    "  img_crop = img_src[y:y+h,x:x+w]\n",
    "  return img_crop\n",
    "\n",
    "def autocrop_sky(img_src, crop_thresh=0.98, sky_thresh=150):\n",
    "  \"\"\"\n",
    "  Automatically crops sky from the top of images when percentage of the ROW\n",
    "  (default = 98%) is white based on threshold of pixel value (default = 150).\n",
    "  Used after FINAL round of image stitching.\n",
    "\n",
    "  Arguments:\n",
    "  img_src       --  numpy array image, color; source image where sky is to be cropped.\n",
    "  crop_thresh   --  float; if more than this value (default = 98%) of the row is white, the row is cropped.\n",
    "  sky_thresh    --  int; defines pixel brightness threshold; if pixel value is greater than this value\n",
    "                    (default = 150), the row is cropped.\n",
    "\n",
    "  Returns:\n",
    "  img_crop      --  numpy array image, color; image cropped to where most of row (i.e. greater than threshold) is black.\n",
    "  \"\"\"\n",
    "  # convert to gray and threshold image\n",
    "  gray = cv2.cvtColor(img_src,cv2.COLOR_BGR2GRAY)\n",
    "  _,thresh = cv2.threshold(gray,sky_thresh,255,cv2.THRESH_BINARY)\n",
    "  # the target is the value if all pixels in row times the crop threshold are white\n",
    "  target = 255 * crop_thresh * thresh.shape[1]\n",
    "  summed = np.sum(thresh, axis=1)\n",
    "  # iterate through array, collect indexes where the value of a summed row exceeds the target\n",
    "  for idx3 in range(summed.shape[0]):\n",
    "    if summed[idx3] > target:\n",
    "      thresh[idx3,:] = 0\n",
    "  # crop image according to indexes\n",
    "  thresh[0:10,:] = 0 # the first rows are often non-zero due to black lines introduced during image stitching\n",
    "  nonzero = np.nonzero(np.sum(thresh, axis = 1))[0]\n",
    "  img_crop = img_src[nonzero[0]:nonzero[-1],:]\n",
    "  return img_crop\n",
    "\n",
    "\n",
    "def stitch_six(img_lst, show_images= False, save_file=False, save_directory=None, save_filename=None, write_logs=False):\n",
    "  \"\"\"\n",
    "  Stitches six images together in three rounds, including automatic cropping of columns and/or rows\n",
    "  (as required) in between rounds of stitching, with final crop of the sky.\n",
    "\n",
    "  Given input images 0,1,2,3,4, and 5, there are 3 rounds of image stitching:\n",
    "  First round images: 01, 23, 45\n",
    "  Second round images: 0123, 0145\n",
    "  Third round images: 012345 (i.e. all images)\n",
    "\n",
    "  Arguments:\n",
    "  img_lst         --  list; a list of 6 images to be stitched together,\n",
    "                      each of which is a color numpy array inage.\n",
    "  show_images     --  boolean, whether the images should be plotted using matplotlib upon completion.\n",
    "  save_file       --  boolean, whether the files should be saved upon completion of the stitching.\n",
    "  save_directory  --  string; location where the file should be saved to.\n",
    "  save_filename   --  string; name of the file to be saved, e.g. 'stitch6.jpg'.\n",
    "  write_logs      --  boolean; whether to write JSON file to log stitching keypoint matches for later analysis.\n",
    "\n",
    "  Returns:\n",
    "  final_crop      --  numpy array image, color; the stitched and cropped image result.\n",
    "  \"\"\"\n",
    "\n",
    "  stitched_lst1 = [] # first round of stitched images to be stored in this list\n",
    "  stitched_lst2 = [] # second round of stitched images to be stored in this list\n",
    "  crop_lst1 = [] # first round of cropped images to be stored in this list\n",
    "  crop_lst2 = [] # second round of cropped images to be stored in this list\n",
    "  matches_lst = [] # list where number of keypoint matches will be saved\n",
    "  i, j, k, l, m = 0, 0, 0, 0, 0 # reset indexes\n",
    "\n",
    "  # Show original images\n",
    "  if show_images == True:\n",
    "    num_cols = 3\n",
    "    num_rows = 2\n",
    "    idx = 0\n",
    "    plt.figure(figsize=[10,10])\n",
    "    for idx in range(0, len(img_lst)):\n",
    "      plt.subplot(num_rows, num_cols, idx + 1)\n",
    "      plt.title('Original Images')\n",
    "      plt.axis(\"off\")\n",
    "      plt.imshow(img_lst[idx])\n",
    "\n",
    "  # First round of image stitching --> six images in img_lst: 0, 1, 2, 3, 4, and 5\n",
    "  # Upon stitching, three resulting stitched images: 01, 23, and 45, stored in stitched_lst1\n",
    "  for i in range(0,len(img_lst)-1,2):\n",
    "    # call stitch_it function\n",
    "    stiched_img, num_matches = stitch_it(img_lst[i], img_lst[i+1])\n",
    "    matches_lst.append(num_matches)\n",
    "    stitched_lst1.append(stiched_img)\n",
    "\n",
    "  if show_images == True:\n",
    "    num_cols = 3\n",
    "    num_rows = 1\n",
    "    idx = 0\n",
    "    plt.figure(figsize=[10,10])\n",
    "    for idx in range(0, len(stitched_lst1)):\n",
    "      plt.subplot(num_rows, num_cols, idx + 1)\n",
    "      plt.title('Stitch 1')\n",
    "      plt.axis(\"off\")\n",
    "      plt.imshow(stitched_lst1[idx])\n",
    "\n",
    "  # Crop black columns from first-round stitches\n",
    "  for j in range(len(stitched_lst1)):\n",
    "    crop = autocrop_col(stitched_lst1[j])\n",
    "    crop_lst1.append(crop)\n",
    "\n",
    "  if show_images == True:\n",
    "    num_cols = 3\n",
    "    num_rows = 1\n",
    "    idx = 0\n",
    "    plt.figure(figsize=[10,10])\n",
    "    for idx in range(0, len(crop_lst1)):\n",
    "      plt.subplot(num_rows, num_cols, idx + 1)\n",
    "      plt.title('Stitch 1 Crop')\n",
    "      plt.axis(\"off\")\n",
    "      plt.imshow(crop_lst1[idx])\n",
    "\n",
    "  # Second round of image stitching --> three images in stitched_lst1: 01, 23, and 45\n",
    "  # Upon stitching, two resulting stitched images: 0123, and 0145, stored in stitched_lst2\n",
    "  for k in range(len(crop_lst1)-1):\n",
    "    stitched_img2, num_matches = stitch_it(crop_lst1[0], crop_lst1[k+1])\n",
    "    matches_lst.append(num_matches)\n",
    "    stitched_lst2.append(stitched_img2)\n",
    "\n",
    "  if show_images == True:\n",
    "    num_cols = 2\n",
    "    num_rows = 1\n",
    "    idx = 0\n",
    "    plt.figure(figsize=[10,10])\n",
    "    for idx in range(0, len(stitched_lst2)):\n",
    "      plt.subplot(num_rows, num_cols, idx + 1)\n",
    "      plt.title('Stitch 2')\n",
    "      plt.axis(\"off\")\n",
    "      plt.imshow(stitched_lst2[idx])\n",
    "\n",
    "  # Crop black rows from second-round stitches\n",
    "  for l in range(len(stitched_lst2)):\n",
    "    crop2 = autocrop_row(stitched_lst2[l])\n",
    "    crop_lst2.append(crop2)\n",
    "\n",
    "  if show_images == True:\n",
    "    num_cols = 2\n",
    "    num_rows = 1\n",
    "    idx = 0\n",
    "    plt.figure(figsize=[10,10])\n",
    "    for idx in range(0, len(crop_lst2)):\n",
    "      plt.subplot(num_rows, num_cols, idx + 1)\n",
    "      plt.title('Stitch 2 Crop')\n",
    "      plt.axis(\"off\")\n",
    "      plt.imshow(crop_lst2[idx])\n",
    "\n",
    "  # Third and final round of image stitching --> two images in stitched_lst2: 0123 and 0145\n",
    "  # Upon stitching, only one stitched image: 012345, stored in stitched_img3\n",
    "  for m in range(len(crop_lst2)-1):\n",
    "    stitched_img3, num_matches = stitch_it(crop_lst2[0], crop_lst2[m+1])\n",
    "    matches_lst.append(num_matches)\n",
    "\n",
    "  if show_images == True:\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.title('Final Stitch')\n",
    "    plt.imshow(stitched_img3)\n",
    "\n",
    "  # Crop sky and any remaining black columns/rows from third-round stitches\n",
    "  final_crop = autocrop_col(stitched_img3)\n",
    "  final_crop = autocrop_row(final_crop)\n",
    "  final_crop = autocrop_sky(final_crop)\n",
    "\n",
    "  if show_images == True:\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.title('Final Crop')\n",
    "    plt.imshow(final_crop)\n",
    "\n",
    "  if save_file == True:\n",
    "    # Write file to disk\n",
    "    cv2.imwrite(os.path.join(save_directory, save_filename), cv2.cvtColor(final_crop, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  if write_logs == True:\n",
    "    # Log matches into JSON file for later analysis\n",
    "    match_logpath = os.path.join(MAIN_FOLDER,'match_log.json')\n",
    "    match_data = {}\n",
    "    match_data['image_id'] = image_id\n",
    "    match_data['matches'] = matches_lst\n",
    "    with open(match_logpath, 'a') as f:\n",
    "      f.write(json.dumps(match_data, indent=4))\n",
    "    f.close\n",
    "\n",
    "  return final_crop\n",
    "\n",
    "\n",
    "def stitch_four(img_lst, show_images=False, save_file=False, save_directory=None, save_filename=None, write_logs=False):\n",
    "  \"\"\"\n",
    "  Stitches four images together in two rounds, including automatic cropping of columns and/or rows\n",
    "  (as required) in between rounds of stitching, with final crop of the sky.\n",
    "\n",
    "  Given input images 0,1,2, and 3 there are 2 rounds of image stitching:\n",
    "  First round images: 01, 23\n",
    "  Second round images: 0123 (i.e. all images)\n",
    "\n",
    "  Arguments:\n",
    "  img_lst         --  list; a list of 6 images to be stitched together,\n",
    "                      each of which is a color numpy array inage.\n",
    "  show_images     --  boolean, whether the images should be plotted using matplotlib upon completion.\n",
    "  save_file       --  boolean, whether the files should be saved upon completion of the stitching.\n",
    "  save_directory  --  string; location where the file should be saved to.\n",
    "  save_filename   --  string; name of the file to be saved, e.g. 'stitch6.jpg'.\n",
    "  write_logs      --  boolean; whether to write JSON file to log stitching keypoint matches for later analysis.\n",
    "\n",
    "  Returns:\n",
    "  final_crop      --  numpy array image, color; the stitched and cropped image result.\n",
    "  \"\"\"\n",
    "  stitched_lst1 = [] # first round of stitched images to be stored in this list\n",
    "  crop_lst1 = [] # first round of cropped images to be stored in this list\n",
    "  matches_lst = [] # list where number of keypoint matches will be saved\n",
    "  i, j, k = 0, 0, 0 # reset indexes\n",
    "\n",
    "  # Show original images\n",
    "  if show_images == True:\n",
    "    num_cols = 2\n",
    "    num_rows = 2\n",
    "    idx = 0\n",
    "    plt.figure(figsize=[10,10])\n",
    "    for idx in range(0, len(img_lst)):\n",
    "      plt.subplot(num_rows, num_cols, idx + 1)\n",
    "      plt.title('Original Images')\n",
    "      plt.axis(\"off\")\n",
    "      plt.imshow(img_lst[idx])\n",
    "\n",
    "  # First round of image stitching --> four images in img_lst: 0, 1, 2, and 3\n",
    "  # Upon stitching, two resulting stitched images: 01 and 23, stored in stitched_lst1\n",
    "  for i in range(0,len(img_lst)-1,2):\n",
    "    stiched_img, num_matches = stitch_it(img_lst[i], img_lst[i+1])\n",
    "    matches_lst.append(num_matches)\n",
    "    stitched_lst1.append(stiched_img)\n",
    "\n",
    "  if show_images == True:\n",
    "    num_cols = 2\n",
    "    num_rows = 1\n",
    "    idx = 0\n",
    "    plt.figure(figsize=[10,10])\n",
    "    for idx in range(0, len(stitched_lst1)):\n",
    "      plt.subplot(num_rows, num_cols, idx + 1)\n",
    "      plt.title('Stitch 1')\n",
    "      plt.axis(\"off\")\n",
    "      plt.imshow(stitched_lst1[idx])\n",
    "\n",
    "  # Crop black columns from first-round stitches\n",
    "  for j in range(len(stitched_lst1)):\n",
    "    crop = autocrop_col(stitched_lst1[j])\n",
    "    crop_lst1.append(crop)\n",
    "\n",
    "  if show_images == True:\n",
    "    num_cols = 3\n",
    "    num_rows = 1\n",
    "    idx = 0\n",
    "    plt.figure(figsize=[10,10])\n",
    "    for idx in range(0, len(crop_lst1)):\n",
    "      plt.subplot(num_rows, num_cols, idx + 1)\n",
    "      plt.title('Stitch 1 Crop')\n",
    "      plt.axis(\"off\")\n",
    "      plt.imshow(crop_lst1[idx])\n",
    "\n",
    "  # Second and final round of image stitching --> two images in img_lst: 01 and 23\n",
    "  # Upon stitching, only one stitched image: 0123, stored in stitched_img2\n",
    "  for k in range(len(crop_lst1)-1):\n",
    "    stitched_img2, num_matches = stitch_it(crop_lst1[0], crop_lst1[k+1])\n",
    "    matches_lst.append(num_matches)\n",
    "\n",
    "  if show_images == True:\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.title('Stitch 2')\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(stitched_img2)\n",
    "\n",
    "  # Crop sky and any remaining black columns/rows from second-round stitches\n",
    "  final_crop = autocrop_row(stitched_img2)\n",
    "  final_crop = autocrop_col(final_crop)\n",
    "  final_crop = autocrop_sky(final_crop)\n",
    "\n",
    "  if show_images == True:\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.title('Final Crop')\n",
    "    plt.imshow(final_crop)\n",
    "\n",
    "  if save_file == True:\n",
    "    # Write file to disk\n",
    "    cv2.imwrite(os.path.join(save_directory, save_filename), cv2.cvtColor(final_crop, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  if write_logs == True:\n",
    "    # Log matches into JSON file for later analysis\n",
    "    match_logpath = os.path.join(MAIN_FOLDER,'match_log.json')\n",
    "    match_data = {}\n",
    "    match_data['image_id'] = image_id\n",
    "    match_data['matches'] = matches_lst\n",
    "    with open(match_logpath, 'a') as f:\n",
    "      f.write(json.dumps(match_data, indent=4))\n",
    "    f.close\n",
    "\n",
    "  return final_crop\n",
    "\n",
    "\n",
    "def stitch_two(img_lst, show_images=False, save_file=False, save_directory=None, save_filename=None, write_logs=False):\n",
    "  \"\"\"\n",
    "  Stitches two images together in one round, including automatic cropping of columns.\n",
    "  (as required) in between rounds of stitching, with final crop of the sky.\n",
    "\n",
    "  Given input images 0,1 there is 1 round of image stitching:\n",
    "  First round images: 01 (i.e. all images)\n",
    "\n",
    "  Arguments:\n",
    "  img_lst         --  list; a list of 6 images to be stitched together,\n",
    "                      each of which is a color numpy array inage.\n",
    "  show_images     --  boolean, whether the images should be plotted using matplotlib upon completion.\n",
    "  save_file       --  boolean, whether the files should be saved upon completion of the stitching.\n",
    "  save_directory  --  string; location where the file should be saved to.\n",
    "  save_filename   --  string; name of the file to be saved, e.g. 'stitch6.jpg'.\n",
    "  write_logs      --  boolean; whether to write JSON file to log stitching keypoint matches for later analysis.\n",
    "\n",
    "  Returns:\n",
    "  final_crop      --  numpy array image, color; the stitched and cropped image result.\n",
    "  \"\"\"\n",
    "  matches_lst = [] # list where number of keypoint matches will be saved\n",
    "  i = 0 # reset indexes\n",
    "\n",
    "  # Show original images\n",
    "  if show_images == True:\n",
    "    num_cols = 2\n",
    "    num_rows = 1\n",
    "    idx = 0\n",
    "    plt.figure(figsize=[10,10])\n",
    "    for idx in range(0, len(img_lst)):\n",
    "      plt.subplot(num_rows, num_cols, idx + 1)\n",
    "      plt.title('Original Images')\n",
    "      plt.axis(\"off\")\n",
    "      plt.imshow(img_lst[idx])\n",
    "\n",
    "  # First (and only) round of image stitching --> two images in img_lst: 0 and 1\n",
    "  # Upon stitching, one resulting stitched image: 01, stored in stitched_img\n",
    "  for i in range(0,len(img_lst)-1,2):\n",
    "    stitched_img, num_matches = stitch_it(img_lst[i], img_lst[i+1])\n",
    "    matches_lst.append(num_matches)\n",
    "\n",
    "  if show_images == True:\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.title('Stitch 1')\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(stitched_img)\n",
    "\n",
    "  # Crop sky and any remaining black columns/rows from first-round stitches\n",
    "  final_crop = autocrop_col(stitched_img)\n",
    "  final_crop = autocrop_row(final_crop)\n",
    "  final_crop = autocrop_sky(final_crop)\n",
    "\n",
    "  if show_images == True:\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.title('Final Crop')\n",
    "    plt.imshow(final_crop)\n",
    "\n",
    "  if save_file == True:\n",
    "    # Write file to disk\n",
    "    cv2.imwrite(os.path.join(save_directory, save_filename), cv2.cvtColor(final_crop, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  if write_logs == True:\n",
    "    # Log matches into JSON file for later analysis\n",
    "    match_logpath = os.path.join(MAIN_FOLDER,'match_log.json')\n",
    "    match_data = {}\n",
    "    match_data['image_id'] = image_id\n",
    "    match_data['matches'] = matches_lst\n",
    "    with open(match_logpath, 'a') as f:\n",
    "      f.write(json.dumps(match_data, indent=4))\n",
    "    f.close\n",
    "\n",
    "  return final_crop\n",
    "\n",
    "\n",
    "def stitching_main(img_lst, show_images=False, save_file=False, save_directory=None, save_id=None, error_log_dir=PROJECT_DIR, write_logs=False):\n",
    "  \"\"\"\n",
    "  Main stitching function, selects whether to use stitch_two, stitch_four, or stitch_six based on\n",
    "  number of input images.\n",
    "  If there are errors during stitching, the function logs these to the noted path/file, rather\n",
    "  than throwing errors during stitching. Errors occur when images cannot be stitched together,\n",
    "  e.g. if images are too close from GSV camera to building.\n",
    "\n",
    "  Arguments:\n",
    "  img_lst         --  list, a list of 2, 4, or 6 images to be stitched together\n",
    "  show_images     --  boolean, whether the images should be plotted using matplotlib upon completion\n",
    "  save_file       --  boolean, whether the files should be saved upon completion of the stitching\n",
    "  save_directory  --  string, the location where the file should be saved to\n",
    "  save_id         --  string, the file name to save to\n",
    "  save_filename   --  string, the name of the file to be saved, e.g. 'stitch2.jpg'\n",
    "  error_log_dir   --  string, the directory where error logs should be saved to\n",
    "  \"\"\"\n",
    "  if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "\n",
    "  try:\n",
    "    if len(img_lst) == 2:\n",
    "      stitch_two(img_lst, show_images=show_images, save_file=save_file, save_directory=save_directory, save_filename=str(save_id)+'.jpg', write_logs=write_logs)\n",
    "\n",
    "    elif len(img_lst) == 4:\n",
    "      stitch_four(img_lst, show_images=show_images, save_file=save_file, save_directory=save_directory, save_filename=str(save_id)+'.jpg', write_logs=write_logs)\n",
    "\n",
    "    elif len(img_lst) == 6:\n",
    "      stitch_six(img_lst, show_images=show_images, save_file=save_file, save_directory=save_directory, save_filename=str(save_id)+'.jpg', write_logs=write_logs)\n",
    "\n",
    "  except Exception as e:\n",
    "    error_logpath = os.path.join(error_log_dir,'error_log.json')\n",
    "    error_data = {}\n",
    "    error_data['image_id'] = image_id\n",
    "    error_data['error'] = str(e)\n",
    "    with open(error_logpath, 'a') as f:\n",
    "      f.write(json.dumps(error_data, indent=4))\n",
    "    f.close\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cQG47X5hQqm"
   },
   "source": [
    "# For loop to call functions and extract multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "hLspGnEdT7uR"
   },
   "outputs": [],
   "source": [
    "# if folders do not exist, create them\n",
    "if not os.path.exists(MAIN_FOLDER):\n",
    "  os.makedirs(MAIN_FOLDER)\n",
    "if not os.path.exists(STITCH_FOLDER):\n",
    "  os.makedirs(STITCH_FOLDER)\n",
    "\n",
    "# loop through rows of dataframe to extract all images\n",
    "for row in frontlines_df.index:\n",
    "\n",
    "  # initialize empty lists\n",
    "  heading_lst= []\n",
    "  image_lst = []\n",
    "\n",
    "  # extract paramaters from dataframe and set variables for each iteration of the loop, using parse_dataframe function\n",
    "  image_id, id_folder, center_lon, center_lat, corner_a_tup, corner_b_tup, perp_angle = parse_dataframe(row, frontlines_df)\n",
    "  print('image_id: ', image_id)\n",
    "\n",
    "  # get central camera position from GSV API using get_center_camera function\n",
    "  camera_lon, camera_lat, img0 = get_center_camera(perp_angle, FOV, center_lon, center_lat, id_folder, radius=RADIUS, offset_dist=6)\n",
    "  if camera_lon == False:\n",
    "    continue\n",
    "\n",
    "  # calculate heading to left and right corner of building using rotation_one_camera function\n",
    "  heading_left, heading_right = rotation_one_camera(camera_lon, camera_lat, corner_a_tup[0], corner_a_tup[1],\n",
    "                                                    corner_b_tup[0], corner_b_tup[1], perp_angle, fov=FOV, correction_factor=ROTATION_CORRECTION)\n",
    "\n",
    "  # create list of headings to send to GSV API using parse_headings function\n",
    "  heading_lst = parse_headings(perp_angle, heading_left, heading_right)\n",
    "\n",
    "  # get photos from GSV according to headings in head_lst using get_gsv_photos\n",
    "  image_lst = get_gsv_photos(ortho_img = img0, save_folder=id_folder, camera_lon=camera_lon, camera_lat=camera_lat,\n",
    "                             head_lst=heading_lst, pitch_lst=PITCH_LST, fov=FOV, key=KEY, radius=RADIUS)\n",
    "\n",
    "  # using image_lst, stitch photos together and save to directory\n",
    "  stitching_main(image_lst, show_images=False, save_file=True, save_directory=STITCH_FOLDER,\n",
    "                 save_id=image_id, error_log_dir=PROJECT_DIR, write_logs=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "NEXT STEPS:\n",
    "\n",
    "(i) Annotate extracted images using custom Rhino-based tool or other annotation tool.\n",
    "    --> See folder 03_Annotation_tool in this Repository\n",
    "    --> If using the trained YOLOv9 model in this Repository, at a minimum, it is suggested to annotate \n",
    "    images to run a test set and check performance of the model on the local architectural context.\n",
    "    --> Images can also be annotated for additional training and validation sets.\n",
    "\n",
    "(ii) Upon completion of annotations, run deep learning model using extracted images and annotations.\n",
    "    --> Can use pre-trained YOLOv9 model in this Repository as is (if test set outcomes are satisfactory), \n",
    "    and/or with additional training using newly extracted images and annotations.\n",
    "    --> Another deep learning archiecture could also be used to train/validate a new model.\n",
    "\n",
    "(iii) Upon completion of the deep learning stage, the post-scripts to run additional NMS and stratify detections into ground-floor and above-ground-floor\n",
    "    --> See folder 04_Post_scripts_NMS_and_stratify_detections in this Repository.\n",
    "\n",
    "    \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM5qK70DexYkocMEaq0s3kg",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "14vFk-EkZke3vEhn5y5gUespK6u_Ri_UM",
     "timestamp": 1745290756054
    },
    {
     "file_id": "1G0sj3VfSdMmTg0Log1OD0SC6hb2P00HV",
     "timestamp": 1741257164968
    },
    {
     "file_id": "1AiPc7-LxQHDWSG7Jj4EH4RIToh8UyV4A",
     "timestamp": 1712320112759
    },
    {
     "file_id": "11XmJuJAVVolqIzmlxaMh5DYZJmE_k7Xv",
     "timestamp": 1708512584257
    },
    {
     "file_id": "1SKc07MrDZJGeStEtMhIXi8HYq9g-y2m-",
     "timestamp": 1708509432640
    },
    {
     "file_id": "16x2CoL1v9MPqFlCoecnEZ-cocwgOQP2d",
     "timestamp": 1708077695595
    },
    {
     "file_id": "1c9DV9lIty8K0eu83V4LytzXlBlv7mJ83",
     "timestamp": 1707819107215
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
